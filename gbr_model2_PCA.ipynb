{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and run RF model on 2023-24 season. Using a random sample to split and training on 70% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=12277, step=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('exports/processed_gamelogs_top200_ppg_season23_24.csv')\n",
    "df['date_dt'] = pd.to_datetime(df['date_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop home_vs_away and win loss column and set plater name and date of the game as our index. Drop any rows that contains NA values.\n",
    "data = df.drop(columns=['home_vs_away', 'wl'], inplace=False)\n",
    "\n",
    "data.set_index(['player_name', 'date_dt'], inplace=True)\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "# Prepare the features and target\n",
    "X = data[['min_10', 'fgm_10', 'fga_10', 'fg_pct_10', 'fg3m_10', 'fg3a_10', 'fg3_pct_10', 'ftm_10', 'fta_10', \n",
    "        'ft_pct_10','pts_10', 'min_5', 'fgm_5', 'fga_5', 'fg_pct_5', 'fg3m_5', 'fg3a_5', 'fg3_pct_5', 'ftm_5',\n",
    "        'fta_5', 'ft_pct_5', 'pts_5', 'min_3', 'fgm_3', 'fga_3', 'fg_pct_3', 'fg3m_3', 'fg3a_3', 'fg3_pct_3', \n",
    "        'ftm_3', 'fta_3', 'ft_pct_3', 'pts_3', 'min_last', 'fgm_last', 'fga_last', 'fg_pct_last', 'fg3m_last',\n",
    "        'fg3a_last', 'fg3_pct_last', 'ftm_last', 'fta_last', 'ft_pct_last', 'pts_last',\n",
    "        'min_season', 'fgm_season', 'fga_season', 'fg_pct_season', \n",
    "        'fg3m_season', 'fg3a_season', 'fg3_pct_season', 'ftm_season', 'fta_season', 'ft_pct_season','pts_season'\n",
    "        ]]\n",
    "\n",
    "y = data['pts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 53\n",
      "\n",
      "GBR model without PCA:\n",
      "MAE: 3.7738\n",
      "MSE: 24.2397\n",
      "RMSE: 4.9234\n",
      "R² Score: 0.717\n",
      "\n",
      "GBR model with PCA:\n",
      "MAE: 4.0472\n",
      "MSE (with PCA): 27.7632\n",
      "RMSE (with PCA): 5.2691\n",
      "R² Score (with PCA): 0.6758\n",
      "\n",
      "Diff (Positive Value = GBR w/ PCA performed better):\n",
      "MAE Difference: -0.2734 (-7.24%)\n",
      "MSE Difference: -3.5234 (-14.54%)\n",
      "RMSE Difference: -0.3457 (-7.02%)\n",
      "R² Score Difference: 0.0411 (5.74%)\n"
     ]
    }
   ],
   "source": [
    "def run_gbr_with_pca_comparison(features=X, target=y):\n",
    "\n",
    "    random_state = random.randint(1, 100)\n",
    "    print(f\"Random state: {random_state}\\n\")\n",
    "\n",
    "    # Split data into test and training sets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=random_state)\n",
    "\n",
    "\n",
    "    # 1. Train and run model without Scaler and PCA\n",
    "    # Fit and run the model.\n",
    "    model = GradientBoostingRegressor(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "    # 2. Train and run model with Scaler and PCA\n",
    "    # Normalize feature values with Scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Fit PCA model, reduce dataset features to the # of components (n_components) that account for 95% of the variance.\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    # Fit and run the model.\n",
    "    model_pca = GradientBoostingRegressor(random_state=random_state)\n",
    "    model_pca.fit(X_train_pca, y_train)\n",
    "    predictions_pca = model_pca.predict(X_test_pca)\n",
    "\n",
    "\n",
    "    # 3. Evaluate and compare the models.    \n",
    "    # Model 1 - GBR model without PCA and normalization.\n",
    "    mae = (mean_absolute_error(y_test, predictions))\n",
    "    mse = (mean_squared_error(y_test, predictions))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    relative_mae = mae / y_test.mean()  \n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    print(\"GBR model without PCA:\")\n",
    "    print(f\"MAE: {round(mae, 4)}\")\n",
    "    print(f\"MSE: {round(mse, 4)}\")\n",
    "    print(f\"RMSE: {round(rmse, 4)}\")\n",
    "    print(f\"R² Score: {round(r2, 4)}\") \n",
    "\n",
    "    # Model 2 - GBR model with PCA and normalization.\n",
    "    mae_pca = (mean_absolute_error(y_test, predictions_pca))\n",
    "    mse_pca = (mean_squared_error(y_test, predictions_pca))\n",
    "    rmse_pca = np.sqrt(mean_squared_error(y_test, predictions_pca))\n",
    "    r2_pca = r2_score(y_test, predictions_pca)\n",
    "\n",
    "    print(\"\\nGBR model with PCA:\")\n",
    "    print(f\"MAE: {round(mae_pca, 4)}\")\n",
    "    print(f\"MSE (with PCA): {round(mse_pca, 4)}\")\n",
    "    print(f\"RMSE (with PCA): {round(rmse_pca, 4)}\")\n",
    "    print(f\"R² Score (with PCA): {round(r2_pca, 4)}\")\n",
    "\n",
    "    # Calculate and print the differences between the models\n",
    "    mae_diff = mae - mae_pca\n",
    "    mse_diff = mse - mse_pca\n",
    "    rmse_diff = rmse - rmse_pca\n",
    "    r2_diff = r2 - r2_pca\n",
    "\n",
    "    # Calculate percentage differences\n",
    "    mae_diff_pct = (mae_diff / mae) * 100\n",
    "    mse_diff_pct = (mse_diff / mse) * 100\n",
    "    rmse_diff_pct = (rmse_diff / rmse) * 100\n",
    "    r2_diff_pct = (r2_diff / r2) * 100\n",
    "\n",
    "    print(\"\\nDiff (Positive Value = GBR w/ PCA performed better):\")\n",
    "    print(f\"MAE Difference: {round(mae_diff, 4)} ({round(mae_diff_pct, 2)}%)\")\n",
    "    print(f\"MSE Difference: {round(mse_diff, 4)} ({round(mse_diff_pct, 2)}%)\")\n",
    "    print(f\"RMSE Difference: {round(rmse_diff, 4)} ({round(rmse_diff_pct, 2)}%)\")\n",
    "    print(f\"R² Score Difference: {round(r2_diff, 4)} ({round(r2_diff_pct, 2)}%)\")\n",
    "\n",
    "# Run the function.\n",
    "run_gbr_with_pca_comparison()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
